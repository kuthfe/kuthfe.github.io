<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

    <meta name="twitter:card" content="summary" />
    <meta name="twitter:creator" content="@ch402" />
    <meta property="og:url" content="https://colah.github.io/notes/interp-v-neuro/" />
    <meta property="og:title" content="Interpretability vs Neuroscience [rough note]" />
    <meta property="og:description"
        content="A list of advantages that make understanding artificial nerural networks much easier than biological ones." />

    <title>Interpretability vs Neuroscience [rough note] -- colah's blog</title>

    <link rel="stylesheet" href="../../fonts/Serif/cmun-serif.css" />
    <link rel="stylesheet" href="../../fonts/Serif-Slanted/cmun-serif-slanted.css" />

    <!--BOOTSTRAP-->
    <link href="../../bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <!--mobile first-->
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!--removed html from url but still is html-->
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

    <!--font awesome-->
    <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">

    <!--fonts: allan & cardo-->
    <link href="http://fonts.googleapis.com/css?family=Droid+Serif" rel="stylesheet" type="text/css">
    <link href="http://fonts.googleapis.com/css?family=Droid+Sans" rel="stylesheet" type="text/css">

    <link href="../../css/sticky-footer-navbar.css" rel="stylesheet">

    <link href="../../css/default.css" rel="stylesheet">

    <link href="../../comments/inlineDisqussions.css" rel="stylesheet">

    <!--Highlight-->
    <link href="../../highlight/styles/github.css" rel="stylesheet">

    <link href="../../favicon.ico" rel="shortcut icon" />

    <!--<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>-->
    <script type="text/javascript"
        src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    <style>
        .post {
            width: 170px;
            min-height: 175px;
            padding-left: 5px;
            padding-right: 5px;
            float: left;
            border-left: 1px solid #CCC;
            background-color: white;
        }

        div a:first-of-type .post {
            border-left: none;
        }

        .post:hover {
            filter: brightness(90%);
        }

        .post h3 {
            margin: 5px;
            font-size: 75%;
            text-align: center
        }

        .post h4 {
            margin: 0px;
            font-size: 50%;
            text-align: center
        }

        .post img {
            margin: 0px;
            padding: 2px;
            margin-bottom: 10px;
            width: 100%;
            height: 155px
        }
    </style>

    <script>
        (function (i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date(); a = s.createElement(o),
                m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-49811703-1', 'colah.github.io');
        ga('require', 'linkid', 'linkid.js');
        ga('require', 'displayfeatures');
        ga('send', 'pageview');

    </script>

</head>

<body>
    <div id="wrap">
        <nav class="navbar navbar-inverse navbar-static-top" role="navigation">
            <div class="container">
                <!--Toggle header for mobile-->
                <div class="navbar-header">
                    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand active" href="../../" style="font-size:20px;">colah's blog</a>
                </div>
                <!--normal header-->
                <div class="navbar-collapse collapse">
                    <ul class="nav navbar-nav navbar-right">
                        <li><a href="../../"><span class="glyphicon glyphicon-pencil"></span> Blog</a></li>
                        <li><a href="../../about.html"><span class="glyphicon glyphicon-user"></span> About</a></li>
                        <li><a href="../../contact.html"><span class="glyphicon glyphicon-envelope"></span> Contact</a>
                        </li>
                    </ul>
                </div>
                <!--/.nav-collapse -->
            </div>
        </nav>


        <div id="content">
            <div class="container">
                <div class="row">
                    <div class="col-md-8">
                        <h1>Interpretability vs Neuroscience</h1>
                        <div style="font-size: 160%; margin-bottom: 12px; line-height: 120%;">Six major advantages which
                            make artificial neural networks much easier to study than biological ones.</div>
                        <div class="info">
                            <p style="font-family:CMSS; font-size:120%">Posted on March 12th, 2021</p>
                        </div>

                        <br>

                        <div
                            style='background: #F8F8F8; border: 1px solid #AAA; border-radius: 8px; padding: 12px; font-size: 90%; color: #444; font-style: italic;'>
                            This article is a rough note.
                            Writing rough notes allows me share more content, since polishing takes lots of time.
                            While I hope it's useful, it's likely lower quality and less carefully considered than my
                            usual articles.
                            It's very possible I wouldn't stand by this content if I thought about it more.
                        </div>

                        <br>
                        <br>

                        <style>
                            body {
                                text-align: left !important;
                            }

                            h2 {
                                margin-top: 40px;
                                font-size: 115% !important;
                            }

                            h1 div {
                                font-size: 80%;
                                color: #999;
                            }

                            h2 div {
                                margin-bottom: 8px;
                                font-size: 100%;
                                color: #999;
                                margin-top: 60px;
                            }

                            figcaption {
                                font-size: 80%;
                                color: #777;
                                line-height: 115%;
                            }
                        </style>


                        <p>
                            I study what goes on inside artificial neural networks.
                            I don’t know anything much about actual neuroscience, but I'm sometimes struck by how much
                            easier my job is than a neuroscientist's.
                        </p>

                        <p>
                            This essay lists advantages that make it easier to understand artificial neural networks.
                            If we're to make rapid progress on understanding artificial neural networks
                            — when countless brilliant neuroscientists have only started to understand the human brain
                            after decades of research —
                            we should probably be trying to exploit these advantages as ruthlessly as possible.
                        </p>

                        <!--<p>
                            (Aside: I think there's an incredible amount of rich structure to be found inside artificial
                            neural networks.
                            This includes things like <a href="https://distill.pub/2021/multimodal-neurons/">mulitmodal
                                neurons</a> where are very similar to results in
                            neuroscience, and may make artificial neural networks an interesting target of
                            investigation. )
                        </p>-->


                        <h2>
                            <div>Advantage 1</div>
                            You can get the responses of all neurons for arbitrarily many stimuli.
                        </h2>

                        <p>
                            In neuroscience, one is limited in the number of neurons they can record from, their ability
                            to select the neurons they record, and the number of stimuli they can record responses to.
                            For artificial neural networks, we can record the responses of <b>all neurons</b> to
                            <b>arbitrarily many</b> stimuli.
                            For example, it’s not unusual to use recordings of how every single neuron in a network
                            responds to millions of natural stimuli.
                        </p>

                        <p>
                            There's no lab work involved.
                            Turn arounds are much faster than biological experiments (essentially instant for small
                            scale recording).
                            There's no recording noise. No synaptic fatigue.
                            And if you don't get the recordings you need the first time, you can go back and record
                            again from the exact same neurons, which haven't changed at all.
                        </p>

                        <h2>
                            <div>Advantage 2</div>
                            Not only do you have the connectome, you have the weights!
                        </h2>

                        <p>
                            A major undertaking in neuroscience is the attempt to access the connectome — the graph of
                            how neurons in a brain connect.
                            Even if they succeed, they won’t know the weights of those connections.
                            Are they excitatory or inhibitory?
                            How strongly excitatory or inhibitory are they?
                        </p>

                        <p>
                            With artificial neural networks, all the connections and weights are simply there for us to
                            look at.
                            And since we also know how these artificial neurons are computed, in principle we have
                            everything we need to just reason through and understand the neural network.
                        </p>

                        <p>This is tricky, but if you’re willing to look you can literally read algorithms directly off
                            the weights of the network. This is one of the main ideas behind <a
                                href="https://distill.pub/2020/circuits/zoom-in/">circuits</a>.

                        <figure style='max-width: 650px; margin-top: 40px; margin-bottom: 40px;'>
                            <a href="https://distill.pub/2020/circuits/zoom-in/"><img src="car.png"
                                    style='max-width: 645px;'></a>
                            <figcaption>A simple example of how neural network weights can reflect underlying
                                mechanisms: a car detector is composed from neurons in the previous layer responding to
                                parts of a car in the appropriate arrangement (figure taken from <a
                                    href="https://distill.pub/2020/circuits/zoom-in/">Olah et al, 2020</a>).
                            </figcaption>
                        </figure>


                        <h2>
                            <div>Advantage 3</div>
                            Weight-tying massively reduces the number of unique neurons!
                        </h2>

                        <p>
                            Artificial neural networks often leverage a technique called <i>weight-tying</i>, in which
                            we force many neurons to have the same weights. The most common use of this is in
                            convolutional neural networks, where each neuron has translated copies of itself with the
                            same weights. (If you're unfamiliar, see my tutorial on <a
                                href="http://colah.github.io/posts/2014-07-Conv-Nets-Modular/">conv nets and weight
                                tying</a>.)
                        </p>

                        <p>
                            The effect of weight-tying on interpretability is really under-appreciated.
                            For example, in ImageNet conv nets, weight-tying often reduces the number of unique neurons
                            in early vision by 10,000x or even more!
                            This results in artificial neural networks having many fewer neurons for early vision than
                            their biological counterparts.
                            For example, V1 in Human vision is about 150,000,000 neurons, <a
                                href="https://distill.pub/2020/circuits/early-vision/">early vision in InceptionV1</a>
                            (very expansively defined) is only about 1,000 neurons.
                            This means we can just literally study every single neuron.
                        </p>



                        <h2>
                            <div>Advantage 4</div>
                            Establishing causality by optimizing the input (feature visualization)
                        </h2>

                        <p>
                            In my experience, one of the thorniest issues in understanding neurons in artificial
                            networks is separating correlation from causation.
                            Does a neuron detect a dog head? Or does it just detect part of a dog head? Perhaps it just
                            detects an ear, or an eye, or fur parting in a specific way.
                            Perhaps it detects something that has no intrinsic relationship to dog heads, but is really
                            correlated with their presence.
                            Framing this issue as "correlation vs causation", while true, perhaps understates the
                            problem.
                            There's a second very closely related problem: we don't know what the space of likely
                            functions a neuron might perform is.
                            So we can't just pin down a couple hypotheses and devise an experiment to separate them.
                        </p>

                        <p>
                            I imagine this is also a challenge in neuroscience.
                        </p>

                        <p>
                            Artificial neural networks offer us an immensely useful tool for solving this which we often
                            call <a href="https://distill.pub/2017/feature-visualization/">feature visualization</a>.
                            We create stimuli “from scratch” to strongly activate neurons (or combinations of neurons)
                            in artificial neural networks, by starting with random noise and optimizing the input.
                            The key property of feature visualization is that anything in the resulting visualization
                            there because it caused the neuron to fire more.
                            If feature visualization gives you a fully formed dog head with eyes and ears arranged
                            appropriately, it must be detecting an entire dog head.
                            If it just gives an eye, it's probably only (or at least primarily) responding to that.
                            If it was detecting a watermark or something in the background, feature visualization would
                            render that.
                            (There's an important caveat about the regularization of feature visualizations; see
                            discussion in the section of our tutorial titled <a
                                href="https://distill.pub/2017/feature-visualization/#regularization">"The Spectrum of
                                Regularization"</a>.)
                        </p>

                        <p>Optimizing inputs is also how adversarial examples were discovered!

                        <p>Recent efforts in neuroscience have tried to develop similar methods [], by using an
                            artificial neural network as a proxy for a biological one. This work is very interesting,
                            but it’s unclear they give you the same ability to establish a causal link. It seems hard to
                            exclude the possibility that the resulting stimulus might have content which causes the
                            artificial neurons predicting the biological neuron to fire more, but aren't causally
                            necessary for the biological neuron to fire.


                        <h2>
                            <div>Advantage 5</div>
                            Interventions, Ablations, and Edits
                        </h2>

                        <p>
                            Optogenetics has been a major methodological advance for neuroscience in allowing
                            neuroscientists to temporarily ablate neurons, or to force them to activate.
                            This is a powerful tool for interrogating neural circuits and establishing causality.
                        </p>

                        <p>
                            Artificial neural networks are trivial to manipulate at the level of neurons.
                            One can easily ablate neurons or set them to particular activations.
                            But one can also do more powerful "circuit editing" where one modifies parameters at a finer
                            grained level.
                        </p>

                        <p>
                            This is still early days, but we've already seen interesting examples.
                            In image generation, <a href="https://gandissect.csail.mit.edu/">Bau et al., 2018</a> show
                            that
                            you can ablate neurons to remove objects like tress and windows from generated images.
                            In RL, <a href="https://distill.pub/2020/understanding-rl-vision/">Hilton et al., 2020</a>
                            show
                            that you can ablate features to blind an agent to a particular enemy while leaving other
                            competencies in tact. More recently, <a
                                href="https://distill.pub/2020/circuits/curve-circuits/">Cammarata et al, 2021</a>
                            reimplements a large chunk of neural network from scratch, and then splices it into a model.
                        </p>


                        <h2>
                            <div>Advantage 6</div>
                            We can study the exact same model.
                        </h2>

                        <p>Neuroscientists might study a model organism species, but each brain they study has different
                            neurons. If one neuroscientist reports on an interesting neuron they found, other
                            neuroscientists can't directly study that same neuron. In fact, the neuroscientists studying
                            the original neuron will quickly lose access to it: probes can't be left in indefinitely,
                            organisms die, human subjects leave, and even setting that aside neurons change over time.
                        </p>

                        <p>
                            Studying artificial networks, we can collaboratively reverse engineer the same “brain",
                            building on each other.
                            My collaborators and I all know that in "canonical InceptionV1", 4c:447 is a car detector.
                            In fact, when a colleague at another institution makes neural network and <a
                                href="https://twitter.com/zzznah/status/1245746358369374214">posts it on twitter</a>, I
                            can recognize by eye the neurons he used.
                            This is entertaining, but reflects something which I think is quite remarkable:
                            we have a shared web of thousands of "footholds" into InceptionV1, consisting of neurons we
                            understand fairly well and know the connections between, which makes it massively easier to
                            explore.
                        </p>


                        <br>

                        <h2>
                            <div>Bonus</div>Reduced Moral Murkiness
                        </h2>

                        <p>
                            I care intensely about the welfare of animals.
                            I'm willing to accept that the suffering of animals can be outweighed by the benefit of the
                            research.
                            But I feel very fortunate to not need to make that call -- to wonder if, for each
                            experiment, the benefit is sufficient to justify the suffering.
                            (Although I do think it's worth thinking quite critically about whether there is a point
                            where we need to start extending moral patienthood to artificial neural networks.)
                        </p>

                        <p>
                            I realize the above may seem sanctimonious to those who don't share my values.
                            At a more pragmatic level, artificial neural networks mean you don't need to work with IRBs.
                        </p>




                        <div id="disqus_thread"></div>

                        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
                        <script src="http://code.jquery.com/jquery-1.10.1.min.js"></script>

                        <script src="../../comments/inlineDisqussions.js"></script>
                        <script src="../../js/disqus.js"></script>

                    </div>
                    <div class="col-md-4"></div>
                </div>
            </div>
        </div>



    </div>

    <!-- jQuery-->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
    <script src="http://code.jquery.com/jquery-1.10.1.min.js"></script>

    <script src="../../bootstrap/js/bootstrap.min.js"></script>

    <script src="../../highlight/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    <script src="../../js/footnotes.js"></script>

    <script src="../../comments/inlineDisqussions.js"></script>

    <noscript>Enable JavaScript for footnotes, Disqus comments, and other cool stuff.</noscript>

</body>

</html>